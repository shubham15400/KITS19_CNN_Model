{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing case: case_00000\n",
      "Processing case: case_00001\n",
      "Processing case: case_00002\n",
      "Processing case: case_00003\n",
      "Processing case: case_00004\n",
      "Processing case: case_00005\n",
      "Processing case: case_00006\n",
      "Processing case: case_00007\n",
      "Processing case: case_00008\n",
      "Processing case: case_00009\n",
      "Processing case: case_00010\n",
      "Processing case: case_00011\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions ---\n",
    "def load_case(data_dir, case_id, margin=5):\n",
    "    \"\"\"\n",
    "    Load a single case's imaging and segmentation data.\n",
    "    \"\"\"\n",
    "    case_path = os.path.join(data_dir, case_id)\n",
    "    \n",
    "    # Load imaging data\n",
    "    image_path = os.path.join(case_path, \"imaging.nii.gz\")\n",
    "    image = sitk.ReadImage(image_path)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    # Load segmentation data\n",
    "    mask_path = os.path.join(case_path, \"segmentation.nii.gz\")\n",
    "    mask = sitk.ReadImage(mask_path)\n",
    "    mask_array = sitk.GetArrayFromImage(mask)\n",
    "    \n",
    "    # Crop around the non-zero region\n",
    "    non_zero = np.array(np.nonzero(mask_array))\n",
    "    start = np.maximum(non_zero.min(axis=1) - margin, 0)\n",
    "    end = np.minimum(non_zero.max(axis=1) + margin, mask_array.shape)\n",
    "    slices = tuple(slice(s, e) for s, e in zip(start, end))\n",
    "    \n",
    "    return image_array[slices], mask_array[slices]\n",
    "\n",
    "def normalize_image(image_array):\n",
    "    \"\"\"\n",
    "    Normalize the image array to [0, 1].\n",
    "    \"\"\"\n",
    "    return (image_array - np.min(image_array)) / (np.max(image_array) - np.min(image_array))\n",
    "\n",
    "def resize_image_and_mask(image_array, mask_array, target_shape=(128, 128, 128)):\n",
    "    \"\"\"\n",
    "    Resize the image and mask to the target shape.\n",
    "    \"\"\"\n",
    "    factors = [t / i for t, i in zip(target_shape, image_array.shape)]\n",
    "    resized_image = zoom(image_array, factors, order=1)  # Linear interpolation\n",
    "    resized_mask = zoom(mask_array, factors, order=0)   # Nearest-neighbor for mask\n",
    "    return resized_image, resized_mask\n",
    "\n",
    "def encode_labels(mask_array):\n",
    "    \"\"\"\n",
    "    Encode segmentation masks into binary class labels.\n",
    "    \"\"\"\n",
    "    return (mask_array > 0).astype(int)\n",
    "\n",
    "def augment_data(image_array, mask_array):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to the image and mask.\n",
    "    \"\"\"\n",
    "    if np.random.rand() > 0.5:  # Random horizontal flip\n",
    "        image_array = np.flip(image_array, axis=1)\n",
    "        mask_array = np.flip(mask_array, axis=1)\n",
    "    return image_array, mask_array\n",
    "\n",
    "def preprocess_case(data_dir, case_id, target_shape=(128, 128, 128), augment=False):\n",
    "    \"\"\"\n",
    "    Preprocess a single case: load, crop, normalize, resize, encode labels, and augment.\n",
    "    \"\"\"\n",
    "    # Load and normalize data\n",
    "    image, mask = load_case(data_dir, case_id)\n",
    "    image_normalized = normalize_image(image)\n",
    "    \n",
    "    # Resize to target shape\n",
    "    image_resized, mask_resized = resize_image_and_mask(image_normalized, mask, target_shape)\n",
    "    \n",
    "    # Encode labels\n",
    "    mask_encoded = encode_labels(mask_resized)\n",
    "    \n",
    "    # Apply augmentation if enabled\n",
    "    if augment:\n",
    "        image_resized, mask_encoded = augment_data(image_resized, mask_encoded)\n",
    "    \n",
    "    return image_resized, mask_encoded\n",
    "\n",
    "def load_dataset(data_dir, case_ids, target_shape=(128, 128, 128), augment=False):\n",
    "    \"\"\"\n",
    "    Load and preprocess the entire dataset.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for case_id in case_ids:\n",
    "        print(f\"Processing case: {case_id}\")\n",
    "        image, mask = preprocess_case(data_dir, case_id, target_shape, augment)\n",
    "        dataset.append((image, mask))\n",
    "    return dataset\n",
    "\n",
    "def visualize_preprocessed(image_array, mask_array, slice_idx):\n",
    "    \"\"\"\n",
    "    Visualize slices of the preprocessed CT scan and segmentation mask.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_array[slice_idx], cmap=\"gray\")\n",
    "    plt.title(\"Preprocessed CT Slice\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask_array[slice_idx], cmap=\"jet\", alpha=0.5)\n",
    "    plt.title(\"Preprocessed Mask Slice\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the KiTS19 dataset\n",
    "    data_dir = \"D:\\\\Georgian\\\\ML Programming\\\\Project\\\\kits19\\\\data\"\n",
    "    \n",
    "    # List all cases\n",
    "    case_ids = [case for case in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, case))]\n",
    "    \n",
    "    # List for first 31 cases\n",
    "    case_ids_ = [\n",
    "    \"case_00000\", \"case_00001\", \"case_00002\", \"case_00003\", \"case_00004\",\n",
    "    \"case_00005\", \"case_00006\", \"case_00007\", \"case_00008\", \"case_00009\",\n",
    "    \"case_00010\", \"case_00011\", \"case_00012\", \"case_00013\", \"case_00014\",\n",
    "    \"case_00015\", \"case_00016\", \"case_00017\", \"case_00018\", \"case_00019\",\n",
    "    \"case_00020\", \"case_00021\", \"case_00022\", \"case_00023\", \"case_00024\",\n",
    "    \"case_00025\", \"case_00026\", \"case_00027\", \"case_00028\", \"case_00029\",\n",
    "    \"case_00030\"]\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    target_shape = (128, 128, 128)\n",
    "    dataset = load_dataset(data_dir, case_ids_, target_shape, augment=True)\n",
    "    \n",
    "    # Example: Visualize one case\n",
    "    example_image, example_mask = dataset[0]\n",
    "    slice_idx = example_image.shape[0] // 2\n",
    "    visualize_preprocessed(example_image, example_mask, slice_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (None, 128, 128, 128, 1)\n",
      "y_train shape: (24, 128, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.6348 - loss: 0.6307 - val_accuracy: 0.8466 - val_loss: 0.5546\n",
      "Epoch 2/5\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.8530 - loss: 0.5088 - val_accuracy: 0.8466 - val_loss: 0.4585\n",
      "Epoch 3/5\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.8600 - loss: 0.4308 - val_accuracy: 0.8466 - val_loss: 0.4074\n",
      "Epoch 4/5\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6s/step - accuracy: 0.8597 - loss: 0.3982 - val_accuracy: 0.8466 - val_loss: 0.3565\n",
      "Epoch 5/5\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.8581 - loss: 0.3475 - val_accuracy: 0.8466 - val_loss: 0.3283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8468 - loss: 0.3240\n",
      "Test Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions ---\n",
    "def prepare_data(dataset):\n",
    "    \"\"\"\n",
    "    Convert dataset into features (X) and labels (y).\n",
    "    \"\"\"\n",
    "    X = np.array([item[0] for item in dataset])  # Images\n",
    "    y = np.array([item[1] for item in dataset])  # Masks\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split data into training, validation, and test sets.\n",
    "    \"\"\"\n",
    "    total_samples = len(X)\n",
    "    train_end = int(total_samples * train_ratio)\n",
    "    val_end = train_end + int(total_samples * val_ratio)\n",
    "    \n",
    "    X_train, y_train = X[:train_end], y[:train_end]\n",
    "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "    X_test, y_test = X[val_end:], y[val_end:]\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "# --- Model Architecture ---\n",
    "def create_3d_cnn(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Downsampling\n",
    "    model.add(layers.Conv3D(32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=2))  # Reduces dimensions by half\n",
    "    model.add(layers.Conv3D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=2))  # Reduces dimensions by half again\n",
    "    model.add(layers.Conv3D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=2))  # Reduces dimensions by half again\n",
    "\n",
    "    # Upsampling to restore dimensions\n",
    "    model.add(layers.Conv3DTranspose(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling3D(size=2))  # Upsamples dimensions by 2\n",
    "    model.add(layers.Conv3DTranspose(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling3D(size=2))  # Upsamples dimensions by 2\n",
    "    model.add(layers.Conv3DTranspose(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling3D(size=2))  # Upsamples dimensions by 2\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Conv3D(1, kernel_size=1, activation='sigmoid', padding='same'))  # Binary segmentation\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "def new_func(create_3d_cnn, input_shape):\n",
    "    model = create_3d_cnn(input_shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare data\n",
    "    X, y = prepare_data(dataset)  # Preprocessed dataset\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = split_data(X, y)\n",
    "\n",
    "    # Normalize and reshape inputs\n",
    "    X_train, X_val, X_test = X_train / 1.0, X_val / 1.0, X_test / 1.0  # Normalize\n",
    "    X_train = X_train[..., np.newaxis]  # Add channel axis\n",
    "    X_val = X_val[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    y_train = y_train[..., np.newaxis]  # Shape: (batch_size, depth, height, width, 1)\n",
    "    y_val = y_val[..., np.newaxis]\n",
    "    y_test = y_test[..., np.newaxis]\n",
    "\n",
    "    # Define model\n",
    "    input_shape = X_train.shape[1:]  # e.g., (128, 128, 128, 1)\n",
    "    new_func(create_3d_cnn, input_shape)\n",
    "\n",
    "# Compile, train, and evaluate as before\n",
    "\n",
    "\n",
    "    # Normalize inputs\n",
    "    X_train, X_val, X_test = X_train / 1.0, X_val / 1.0, X_test / 1.0  # Already normalized in preprocessing\n",
    "\n",
    "    # Define model\n",
    "    input_shape = X_train.shape[1:]  # e.g., (128, 128, 128, 1)\n",
    "    model = create_3d_cnn(input_shape)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  # Binary segmentation\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Model output shape:\", model.output_shape)  # Should match y_train shape\n",
    "    print(\"y_train shape:\", y_train.shape)  # Ensure y_train includes the channel dimension\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=5,\n",
    "        batch_size=4,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    # Evaluate model\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "    # # Save model\n",
    "    # model.save(\"kits19_cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
